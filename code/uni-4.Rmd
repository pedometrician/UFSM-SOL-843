---
title: "Unidade IV -- Predição Espacial e Validação Estatística"
output: 
  bookdown::html_document2:
    css: styles.css
lang: pt
bibliography: ~/Dropbox/jabref/biblio.bib
---

```{r, eval=FALSE, echo=FALSE}
rmarkdown::render('uni-4.Rmd', encoding = 'UTF-8', output_dir = "../docs")
```

<div id="summary">
**Temas**: O melhor preditor linear não enviesado empírico. Krigagem simples, ordinária e universal. Funções 
de covariância e os pesos da krigagem. Variância do erro de predição. Suporte de predição. Validação 
estatística de predições espaciais. Validação cruzada. 
</div>

# Predição espacial

Predição significa dizer algo sobre um indivíduo antes de observá-lo. Segundo a terminologia geoestatística
clássica, a predição espacial é chamada de *krigagem*.

A krigagem é um método de interpolação linear que usa os dados das observações e os parâmetros estimados empiricamente 
da função de covariância para fazer predições espaciais. Assim, de maneira geral, o valor predito do sinal $Z$ 
num determinado ponto $\boldsymbol{s}_0$ será o resultado da soma linear ou média ponderada dos dados em sua 
vizinhança. O principal detalhe da krigagem é a determinação dos pesos usados para calcular essa média 
ponderada.

Como na maioria dos problemas de predição linear, o objetivo da krigagem é fazer uma predição que minimize o 
erro de predição, usando como medida a média do erro quadrado de predição $\text{E}[\hat{Z} - Z]^2$. Assim, os
pesos da krigagem são escolhidos de maneira que a média do erro quadrado de predição seja mínima. Nesse 
sentido, podemos dizer que a krigagem é um método de predição linear ótimo e que produz valores não-enviezados,
ou seja, o melhor preditor linear não enviesado empírico.

## Krigagem simples e krigagem ordinária

Segundo a terminologia geoestatística clássica, a *krigagem simples* consiste na predição espacial dos efeitos 
aleatórios, mais especificamente, de uma superfície $\hat{B}(\boldsymbol{s})$. Conforme vimos anteriormente,
os efeitos aleatórios são uma variável aleatória não-observável, que apresenta correlação espacial, e média 
igual à 0 que, assim como a variância, é constante em toda a área de estudo. Contudo, o termo 
*krigagem simples* também é usado para os casos em que nós simplesmente conhecemos a média -- ou podemos 
assumir que a conhecemos -- e, assim, decidimos modelar separadamente os efeitos fixos e os efeitos aleatórios.

Contudo, em geral, nós não conhecemos a média espacial. Nesse caso é preciso estimá-la a partir dos dados que
possuímos em mãos. Se não tivermos segurança de que a média é constante em toda a área de estudo, então podemos
simplesmente pressupor que seja constante em curtos intervalos de distância (hipótese intrínseca). Nesse caso, 
estaremos então fazendo a predição espacial tanto dos efeitos aleatórios como da média espacial (efeito fixo).
Essa prática é conhecida como *krigagem ordinária* na terminologia geoestatística clássica.

A predição espacial do sinal $Z$ em um ponto $\boldsymbol{s}_0$ usando krigagem ordinária é feita usando a 
seguinte equação:

$$\hat{Z}(\boldsymbol{s}_0) = \sum_{i=1}^n \lambda_i y(\boldsymbol{s}_i)$$

onde $\boldsymbol{\lambda}_i$ são os *pesos da predição*, também conhecidos na terminologia
geoestatística clássica como *pesos da krigagem*. Esses são atribuídos a cada uma das $n$ observações que 
possuímos em mãos. Na krigagem ordinária, a principal propriedade dos pesos é que precisam somar, 
obrigatoriamente, 1, ou seja, 

$$\sum_{i=1}^n \lambda_i = 1$$

Essa imposição garante que as predições sejam não-enviesadas.

## Krigagem universal

<!-- $$\hat{Z}(\boldsymbol{s}_0) = \sum_{i=1}^n \lambda_i y(\boldsymbol{s}_i)$$ -->



# Validação estatística

O procedimento da validação cruzada consiste na partição aleatória do conjunto completo de dados em $k$
subconjuntos com aproximadamente o mesmo número de observações. O número de subconjuntos é variável, geralmente
entre 2 e $n$.

A cada passo da validação cruzada, um dos subconjuntos é deixado separado para ser utilizado como conjunto de 
dados de validação. Os demais $k - 1$ subconjuntos são utilizados para constituir o conjunto de calibração do 
modelo linear misto. Calibrado o modelo linear misto, faz-se a predição dos valores da variável de interesse 
nas observações do conjunto deixado separado, o conjunto de dados de validação. Esse procedimento é repetido 
até que cada subconjunto $k$ seja, em algum momento, deixado separado para constituir o conjunto de dados de 
validação enquanto os outros $k - 1$ segmentos são utilizados para estimar os parâmetros do modelo linear 
misto. A partir das predições realizadas para cada um dos $k$ subconjuntos são calculados os erros para avaliar
a qualidade das predições.

A validação externa difere da validação cruzada pelo fato de que os dados usados para validação não são nunca 
usados para estimar os parâmetros do modelo. Assim, a validação cruzada é uma medida obtida na fase inicial de 
trabalho, usando os dados que temos em mãos. Enquanto isso, a validação externa é sempre uma fase posterior, 
realizada usando dados obtidos no campo depois de já termos, por exemplo, produzido o mapa da variável de
interesse com a qual estamos trabalhando.

Como a validação cruzada reusa os dados já usados para estimar os parâmetros do modelo, ela costuma ser 
otimista em relação à qualidade do modelo. Por outro lado, como a validação externa usa dados coletados somente
depois de termos realizado as predições espaciais, sua avaliação costuma ser mais rígida, geralmente mais 
rigorosa do que a validação cruzada.


```{r, message=FALSE, warning=FALSE}
# Pacotes
library(magrittr)
library(dplyr)
library(glue)
library(lattice)
library(latticeExtra)
library(georob)
library(sp)

# Sistemas de referência de coordenadas (Fonte: http://spatialreference.org/ref/epsg/)
wgs84utm22s <- sp::CRS('+proj=utm +zone=22 +south +ellps=WGS84 +datum=WGS84 +units=m +no_defs')
sirgas2000 <- sp::CRS('+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs')

# Rampas de cores
col_soil_var <- topo.colors(100)
```

```{r}
data_folder <- '../data/'
ext <- c('dbf', 'prj', 'shp', 'shx')
files <- c(glue('pedologia25.{ext}'), glue('geologia50.{ext}'))
download <- !all(files %in% list.files(data_folder))
if (download) {
  url <- 'https://github.com/samuel-rosa/UFSM-SOL-843/tree/master/data/'
  url <- glue('{url}{files}')
  destfile <- glue('{data_folder}{files}')
  for (i in 1:length(files)) {
    download.file(url = url[i], destfile = destfile[i])
  }
}
```

```{r}
pedologia25 <- 
  glue('{data_folder}pedologia25.shp') %>% 
  raster::shapefile(stringsAsFactors = TRUE) %>% 
  sp::spTransform(wgs84utm22s)
str(pedologia25, 2)
```

```{r}
geologia50 <- 
  glue('{data_folder}geologia50.shp') %>% 
  raster::shapefile(stringsAsFactors = TRUE) %>% 
  sp::spTransform(wgs84utm22s)
str(geologia50, 2)
```

```{r, message=FALSE, warning=FALSE}
pontos400_o <- febr::observations('ctb0003', which.cols = 'all', progress = FALSE)
pontos400_l <- febr::layers('ctb0003', which.cols = 'all', missing.data = 'keep', progress = FALSE)
id <- c('dataset_id', 'observacao_id')
pontos400 <- 
  merge(pontos400_o, pontos400_l, by.x = id, by.y = id) %>% 
  select(observacao_id, coord_x, coord_y, taxon_sibcs_2009, ca_kcl_aas, argila_, areia_)
rm(pontos400_l, pontos400_o)
sp::coordinates(pontos400) <- ~ coord_x + coord_y
sp::proj4string(pontos400) <- sirgas2000
pontos400 <- sp::spTransform(pontos400, wgs84utm22s)
pontos400$um <- sp::over(x = pontos400, y = pedologia25) %>% unlist()
pontos400$geo <- sp::over(x = pontos400, y = geologia50) %>% unlist()
pontos400in <- pontos400[!is.na(pontos400$um) & !is.na(pontos400$geo), ]
```

```{r lm-fit}
lm_fit <- lm(areia_ ~ um + geo, pontos400in)
summary(lm_fit)
```

```{r vario-direction, fig.asp=1, fig.cap='Variograma direcional dos resíduos do modelo linear do conteúdo de areia na camada superficial do solo.'}
limites <- seq(0, 1500, length.out = 15)
residuals(lm_fit) %>% 
  georob::sample.variogram(
    locations = pontos400in@coords, lag.dist.def = limites,
    xy.angle.def = c(0, 22.5, 67.5, 112.5, 157.5, 180)) %>% 
  plot(type = "b", ylab = 'Semivariância', xlab = 'Distância de separação (km)')
```

```{r, fig.asp=1, message=FALSE, warning=FALSE}
vario <- 
  residuals(lm_fit) %>% 
  georob::sample.variogram(
    locations = pontos400in@coords, lag.dist.def = limites)
vario_fit <- 
  georob::fit.variogram.model(
  vario, variogram.model = 'RMexp', param = c(variance = 20000, nugget = 2000, scale = 500), 
  weighting.method = "cressie", method = "BFGS")
```

```{r}
reml_fit <- georob::georob(
  areia_ ~ um + geo, pontos400in, locations = ~ coord_x + coord_y, variogram.model = 'RMexp', 
  param = c(variance = vario_fit$variogram.object[[1]]$param[['variance']], 
            nugget = vario_fit$variogram.object[[1]]$param[['nugget']], 
            scale = vario_fit$variogram.object[[1]]$param[['scale']]),
  tuning.psi = 1000, control = georob::control.georob(initial.fixef = 'lm'))
summary(reml_fit)
```

```{r vario-reml, fig.asp=1, fig.cap='Variograma amostral (preto) dos resíduos do modelo linear do conteúdo de areia na camada superficial do solo e a função exponencial (vermelho) a ele ajustada.'}
plot(vario, type = "b", xlab = 'Distância de separação (m)', ylab = 'Semivariância')
lines(vario_fit, col = "red", lty = 'dashed')
lines(reml_fit, col = "blue", lty = 'dashed')
```

```{r}
grid <- sp::spsample(pedologia25, 10000, type = 'regular')
grid <- 
  sp::SpatialPointsDataFrame(
    coords = grid@coords, 
    data = data.frame(
      um = sp::over(grid, pedologia25) %>% unlist(),
      geo = sp::over(grid, geologia50) %>% unlist()),
    proj4string = grid@proj4string)
str(grid)
```

```{r}
colnames(grid@coords) <- colnames(pontos400in@coords)
pred_ponto <- predict(reml_fit, newdata = grid, control = georob::control.predict.georob(extended.output = TRUE))
sp::gridded(pred_ponto) <- TRUE
str(pred_ponto)
```

```{r, fig.width=12}
at <- pred_ponto@data[, c("pred", "lower", "upper")] %>% range()
at <- seq(at[1], at[2], length.out = 20)
sp::spplot(pred_ponto, zcol = c("lower", "pred", "upper"), at = at, main = "prediction")
```

```{r}
validacao <- georob::cv(reml_fit)
summary(validacao)
```

```{r}
1 - sum((validacao$pred$data - validacao$pred$pred)^2) / sum((validacao$pred$data - mean(validacao$pred$data))^2)
```

```{r, fig.asp=1}
plot(validacao)
```

